<div align="center">

# ğŸ¤– Projeto A3: Machine Learning Aplicado

### PrediÃ§Ã£o e AnÃ¡lise de Dados - SCIA 2025.2

<img src="https://user-images.githubusercontent.com/74038190/229223263-cf2e4b07-2615-4f87-9c38-e37600f8381a.gif" width="600">

<p>
<img src="https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow?style=for-the-badge" alt="Status"/>
<img src="https://img.shields.io/badge/Valor-40_pontos-blue?style=for-the-badge" alt="Valor"/>
<img src="https://img.shields.io/badge/Entrega-06%2F11%2F2025-red?style=for-the-badge" alt="Entrega"/>
</p>

</div>

---

## ğŸ“‹ Sobre o Projeto

Projeto final da disciplina **Sistemas de Controle e InteligÃªncia Artificial** que consiste no desenvolvimento de um sistema completo de **Machine Learning** para prediÃ§Ã£o e anÃ¡lise de dados.

O projeto utiliza **trÃªs datasets** relacionados a um tema especÃ­fico para desenvolver modelos preditivos, aplicando tÃ©cnicas avanÃ§adas de aprendizado de mÃ¡quina e gerando insights prÃ¡ticos.

### ğŸ¯ Objetivos

- Realizar anÃ¡lise exploratÃ³ria detalhada (EDA)
- Implementar pipeline completo de prÃ©-processamento
- Treinar e avaliar mÃºltiplos modelos de ML
- Comparar resultados com literatura cientÃ­fica
- Gerar recomendaÃ§Ãµes prÃ¡ticas baseadas em dados

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
ğŸ“¦ av3-projeto-ml/
â”£ ğŸ“‚ datasets/
â”ƒ  â”£ ğŸ“„ dataset_01.csv
â”ƒ  â”£ ğŸ“„ dataset_02.csv
â”ƒ  â”£ ğŸ“„ dataset_03.csv
â”ƒ  â”— ğŸ“„ data_sources.md
â”£ ğŸ“‚ notebooks/
â”ƒ  â”£ ğŸ““ 01_analise_exploratoria.ipynb
â”ƒ  â”£ ğŸ““ 02_preprocessamento.ipynb
â”ƒ  â”£ ğŸ““ 03_modelagem_classificacao.ipynb
â”ƒ  â”£ ğŸ““ 04_modelagem_regressao.ipynb
â”ƒ  â”£ ğŸ““ 05_redes_neurais.ipynb
â”ƒ  â”— ğŸ““ 06_resultados_comparativos.ipynb
â”£ ğŸ“‚ src/
â”ƒ  â”£ ğŸ“„ data_processing.py
â”ƒ  â”£ ğŸ“„ feature_engineering.py
â”ƒ  â”£ ğŸ“„ model_training.py
â”ƒ  â”£ ğŸ“„ evaluation.py
â”ƒ  â”— ğŸ“„ visualization.py
â”£ ğŸ“‚ modelos/
â”ƒ  â”£ ğŸ“„ random_forest_model.pkl
â”ƒ  â”£ ğŸ“„ svm_model.pkl
â”ƒ  â”£ ğŸ“„ neural_network.h5
â”ƒ  â”— ğŸ“„ model_comparison.json
â”£ ğŸ“‚ visualizacoes/
â”ƒ  â”£ ğŸ“Š eda/
â”ƒ  â”£ ğŸ“Š correlacoes/
â”ƒ  â”£ ğŸ“Š resultados/
â”ƒ  â”— ğŸ“Š comparativos/
â”£ ğŸ“‚ docs/
â”ƒ  â”£ ğŸ“„ artigo_01.pdf
â”ƒ  â”£ ğŸ“„ artigo_02.pdf
â”ƒ  â”£ ğŸ“„ artigo_03.pdf
â”ƒ  â”— ğŸ“„ analise_artigos.md
â”£ ğŸ“„ relatorio_tecnico.pdf
â”£ ğŸ“„ apresentacao.pdf
â”£ ğŸ“„ requirements.txt
â”— ğŸ“„ README.md
```

---

## ğŸ”¬ Metodologia

### **1. AnÃ¡lise ExploratÃ³ria de Dados (EDA)**

<img src="https://user-images.githubusercontent.com/74038190/212257454-16e3712e-945a-4ca2-b238-408ad0bf87e6.gif" width="300" align="right">

**Objetivos:**
- Examinar estrutura e qualidade dos dados
- Identificar padrÃµes e anomalias
- Visualizar distribuiÃ§Ãµes e correlaÃ§Ãµes
- Detectar outliers e valores ausentes

**TÃ©cnicas Aplicadas:**
- EstatÃ­sticas descritivas
- Matriz de correlaÃ§Ã£o
- GrÃ¡ficos de distribuiÃ§Ã£o
- Box plots e scatter plots
- AnÃ¡lise de variÃ¢ncia

<br clear="right"/>

### **2. PrÃ©-processamento**

**Pipeline de Processamento:**

```python
1. Tratamento de Dados Ausentes
   â”œâ”€â”€ RemoÃ§Ã£o de registros
   â”œâ”€â”€ ImputaÃ§Ã£o por mÃ©dia/mediana
   â””â”€â”€ Preenchimento por algoritmos (KNN)

2. NormalizaÃ§Ã£o e Escalonamento
   â”œâ”€â”€ StandardScaler (z-score)
   â”œâ”€â”€ MinMaxScaler (0-1)
   â””â”€â”€ RobustScaler (outliers)

3. CodificaÃ§Ã£o de VariÃ¡veis CategÃ³ricas
   â”œâ”€â”€ Label Encoding
   â”œâ”€â”€ One-Hot Encoding
   â””â”€â”€ Target Encoding

4. Feature Engineering
   â”œâ”€â”€ CriaÃ§Ã£o de novas features
   â”œâ”€â”€ TransformaÃ§Ãµes (log, sqrt)
   â”œâ”€â”€ Binning
   â””â”€â”€ SeleÃ§Ã£o de features
```

### **3. Modelagem e Treinamento**

<div align="center">

| Algoritmo | Tipo | HiperparÃ¢metros | ValidaÃ§Ã£o |
|:---------:|:----:|:---------------:|:---------:|
| **RegressÃ£o LogÃ­stica** | ClassificaÃ§Ã£o | C, penalty, solver | Cross-Validation |
| **K-Nearest Neighbors** | ClassificaÃ§Ã£o | n_neighbors, weights | Grid Search |
| **Random Forest** | ClassificaÃ§Ã£o/RegressÃ£o | n_estimators, max_depth | Random Search |
| **SVM** | ClassificaÃ§Ã£o | kernel, C, gamma | Grid Search |
| **Redes Neurais** | Deep Learning | layers, neurons, dropout | Early Stopping |

</div>

**DivisÃ£o dos Dados:**
- ğŸŸ¦ **70% Treinamento** - Aprendizado do modelo
- ğŸŸ¨ **15% ValidaÃ§Ã£o** - Ajuste de hiperparÃ¢metros
- ğŸŸ¥ **15% Teste** - AvaliaÃ§Ã£o final

### **4. AvaliaÃ§Ã£o de Modelos**

**MÃ©tricas para ClassificaÃ§Ã£o:**

<table>
<tr>
<td width="50%">

```
ğŸ“Š AcurÃ¡cia
   (TP + TN) / Total

ğŸ“Š PrecisÃ£o
   TP / (TP + FP)

ğŸ“Š Recall (Sensibilidade)
   TP / (TP + FN)

ğŸ“Š F1-Score
   2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall)
```

</td>
<td width="50%">

```
ğŸ“Š Especificidade
   TN / (TN + FP)

ğŸ“Š AUC-ROC
   Ãrea sob curva ROC

ğŸ“Š Matriz de ConfusÃ£o
   VisualizaÃ§Ã£o de erros

ğŸ“Š RelatÃ³rio de ClassificaÃ§Ã£o
   MÃ©tricas por classe
```

</td>
</tr>
</table>

**MÃ©tricas para RegressÃ£o:**

```python
MAE  = Erro MÃ©dio Absoluto
MSE  = Erro QuadrÃ¡tico MÃ©dio
RMSE = Raiz do Erro QuadrÃ¡tico MÃ©dio
RÂ²   = Coeficiente de DeterminaÃ§Ã£o
MAPE = Erro Percentual Absoluto MÃ©dio
```

---

## ğŸ§  Algoritmos Implementados

### **1. RegressÃ£o LogÃ­stica**

<details>
<summary><b>Ver detalhes</b></summary>

Algoritmo linear para classificaÃ§Ã£o binÃ¡ria e multiclasse.

**CaracterÃ­sticas:**
- Simples e interpretÃ¡vel
- RÃ¡pido para treinar
- Bom baseline para comparaÃ§Ã£o

**Uso:**
```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(
    C=1.0,
    penalty='l2',
    solver='lbfgs',
    max_iter=1000
)
model.fit(X_train, y_train)
```

</details>

### **2. K-Nearest Neighbors (KNN)**

<details>
<summary><b>Ver detalhes</b></summary>

Algoritmo baseado em instÃ¢ncias que classifica por proximidade.

**CaracterÃ­sticas:**
- NÃ£o paramÃ©trico
- SensÃ­vel a escala
- Pode ser lento para grandes datasets

**Uso:**
```python
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(
    n_neighbors=5,
    weights='distance',
    metric='euclidean'
)
model.fit(X_train, y_train)
```

</details>

### **3. Random Forest**

<details>
<summary><b>Ver detalhes</b></summary>

Ensemble de Ã¡rvores de decisÃ£o com votaÃ§Ã£o majoritÃ¡ria.

**CaracterÃ­sticas:**
- Robusto a overfitting
- Lida bem com features irrelevantes
- Fornece importÃ¢ncia das features

**Uso:**
```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)
model.fit(X_train, y_train)
```

</details>

### **4. Support Vector Machine (SVM)**

<details>
<summary><b>Ver detalhes</b></summary>

Algoritmo que encontra o hiperplano Ã³timo de separaÃ§Ã£o.

**CaracterÃ­sticas:**
- Efetivo em espaÃ§os de alta dimensÃ£o
- VersÃ¡til com diferentes kernels
- SensÃ­vel a escala dos dados

**Uso:**
```python
from sklearn.svm import SVC

model = SVC(
    kernel='rbf',
    C=1.0,
    gamma='scale',
    probability=True
)
model.fit(X_train, y_train)
```

</details>

### **5. Redes Neurais Artificiais**

<details>
<summary><b>Ver detalhes</b></summary>

Deep Learning com mÃºltiplas camadas de neurÃ´nios.

**CaracterÃ­sticas:**
- Aprende representaÃ§Ãµes complexas
- Requer mais dados
- Necessita tuning cuidadoso

**Uso:**
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential([
    Dense(64, activation='relu', input_shape=(n_features,)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(n_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

</details>

---

## ğŸ“Š Estrutura do RelatÃ³rio TÃ©cnico

### **Documento Final (PDF)**

```
ğŸ“„ RELATÃ“RIO TÃ‰CNICO - PROJETO A3

1. INTRODUÃ‡ÃƒO
   â”œâ”€â”€ ContextualizaÃ§Ã£o do tema
   â”œâ”€â”€ DescriÃ§Ã£o dos datasets
   â”œâ”€â”€ Justificativa e relevÃ¢ncia
   â””â”€â”€ OrganizaÃ§Ã£o do documento

2. OBJETIVOS
   â”œâ”€â”€ Objetivo geral
   â””â”€â”€ Objetivos especÃ­ficos

3. METODOLOGIA
   â”œâ”€â”€ 3.1 Coleta de Dados
   â”œâ”€â”€ 3.2 AnÃ¡lise ExploratÃ³ria
   â”œâ”€â”€ 3.3 PrÃ©-processamento
   â”œâ”€â”€ 3.4 SeleÃ§Ã£o de Algoritmos
   â”œâ”€â”€ 3.5 Treinamento e ValidaÃ§Ã£o
   â””â”€â”€ 3.6 MÃ©tricas de AvaliaÃ§Ã£o

4. REVISÃƒO BIBLIOGRÃFICA
   â”œâ”€â”€ 4.1 Artigo CientÃ­fico 1
   â”‚   â”œâ”€â”€ Resumo e objetivos
   â”‚   â”œâ”€â”€ Metodologia aplicada
   â”‚   â””â”€â”€ Principais resultados
   â”œâ”€â”€ 4.2 Artigo CientÃ­fico 2
   â”‚   â”œâ”€â”€ Resumo e objetivos
   â”‚   â”œâ”€â”€ Metodologia aplicada
   â”‚   â””â”€â”€ Principais resultados
   â””â”€â”€ 4.3 Artigo CientÃ­fico 3
       â”œâ”€â”€ Resumo e objetivos
       â”œâ”€â”€ Metodologia aplicada
       â””â”€â”€ Principais resultados

5. CÃ“DIGO FONTE E IMPLEMENTAÃ‡ÃƒO
   â”œâ”€â”€ 5.1 Estrutura do Projeto
   â”œâ”€â”€ 5.2 Bibliotecas Utilizadas
   â”œâ”€â”€ 5.3 Pipeline de Processamento
   â”œâ”€â”€ 5.4 ImplementaÃ§Ã£o dos Modelos
   â””â”€â”€ 5.5 RepositÃ³rio GitHub

6. RESULTADOS
   â”œâ”€â”€ 6.1 AnÃ¡lise ExploratÃ³ria
   â”‚   â”œâ”€â”€ EstatÃ­sticas descritivas
   â”‚   â”œâ”€â”€ VisualizaÃ§Ãµes
   â”‚   â””â”€â”€ Insights preliminares
   â”œâ”€â”€ 6.2 Performance dos Modelos
   â”‚   â”œâ”€â”€ Dataset 1 - Resultados
   â”‚   â”œâ”€â”€ Dataset 2 - Resultados
   â”‚   â””â”€â”€ Dataset 3 - Resultados
   â”œâ”€â”€ 6.3 ComparaÃ§Ã£o entre Algoritmos
   â”‚   â”œâ”€â”€ Tabelas comparativas
   â”‚   â”œâ”€â”€ GrÃ¡ficos de performance
   â”‚   â””â”€â”€ AnÃ¡lise estatÃ­stica
   â””â”€â”€ 6.4 Feature Importance
       â””â”€â”€ VariÃ¡veis mais relevantes

7. ANÃLISE COMPARATIVA
   â”œâ”€â”€ 7.1 ComparaÃ§Ã£o com Artigo 1
   â”œâ”€â”€ 7.2 ComparaÃ§Ã£o com Artigo 2
   â”œâ”€â”€ 7.3 ComparaÃ§Ã£o com Artigo 3
   â””â”€â”€ 7.4 DiscussÃ£o dos Resultados

8. CONCLUSÃƒO
   â”œâ”€â”€ SÃ­ntese dos resultados
   â”œâ”€â”€ ContribuiÃ§Ãµes do projeto
   â”œâ”€â”€ LimitaÃ§Ãµes encontradas
   â””â”€â”€ RecomendaÃ§Ãµes futuras

9. REFERÃŠNCIAS BIBLIOGRÃFICAS
   â””â”€â”€ Normas ABNT
```

---

## ğŸ¤ ApresentaÃ§Ã£o

### **Estrutura da ApresentaÃ§Ã£o (13/11/2025)**

<div align="center">

| SeÃ§Ã£o | Tempo | ResponsÃ¡vel |
|:-----:|:-----:|:-----------:|
| IntroduÃ§Ã£o e Contexto | 3 min | Membro 1 |
| Metodologia e Datasets | 4 min | Membro 2 |
| ImplementaÃ§Ã£o e CÃ³digo | 4 min | Membro 3 |
| Resultados e AnÃ¡lises | 5 min | Membro 4 |
| ConclusÃµes e Q&A | 4 min | Todos |

**Tempo Total:** 20 minutos

</div>

**Recursos Visuais:**
- Slides objetivos e profissionais
- GrÃ¡ficos e visualizaÃ§Ãµes de dados
- DemonstraÃ§Ã£o ao vivo (opcional)
- ComparaÃ§Ã£o com artigos cientÃ­ficos

---

## ğŸ”§ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### **Requisitos**

```bash
Python 3.10+
Jupyter Notebook ou Google Colab
8GB RAM mÃ­nimo (recomendado 16GB)
```

### **Setup do Ambiente**

```bash
# Clone o repositÃ³rio principal
git clone https://github.com/SEU_USUARIO/SCIA-UNIFACS.git
cd SCIA-UNIFACS/av3-projeto-ml

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Instale dependÃªncias
pip install -r requirements.txt
```

### **DependÃªncias Principais**

```txt
# requirements.txt

# Data Processing
pandas==2.1.0
numpy==1.24.3

# Visualization
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.16.1

# Machine Learning
scikit-learn==1.3.0
scipy==1.11.2

# Deep Learning
tensorflow==2.13.0
keras==2.13.1

# Model Evaluation
imbalanced-learn==0.11.0
xgboost==1.7.6

# Utilities
joblib==1.3.2
pickle5==0.0.12

# Jupyter
jupyter==1.0.0
ipywidgets==8.1.0
```

### **Executar AnÃ¡lises**

```bash
# Iniciar Jupyter
jupyter notebook

# Executar notebooks em ordem:
# 1. notebooks/01_analise_exploratoria.ipynb
# 2. notebooks/02_preprocessamento.ipynb
# 3. notebooks/03_modelagem_classificacao.ipynb
# ... e assim por diante
```

### **Executar Scripts Python**

```bash
# PrÃ©-processamento
python src/data_processing.py

# Treinamento de modelos
python src/model_training.py

# AvaliaÃ§Ã£o
python src/evaluation.py
```

---

## ğŸ“š Fontes de Dados

### **Principais RepositÃ³rios de Datasets**

<table>
<tr>
<td width="50%">

#### ğŸŒ **Online**

**[Kaggle](https://www.kaggle.com/datasets)**
- Maior comunidade de datasets
- CompetiÃ§Ãµes e notebooks pÃºblicos
- API para download automatizado

**[UCI ML Repository](https://archive.ics.uci.edu/)**
- ReferÃªncia acadÃªmica
- Datasets clÃ¡ssicos e validados
- DocumentaÃ§Ã£o detalhada

**[Google Dataset Search](https://datasetsearch.research.google.com/)**
- Busca em mÃºltiplas fontes
- Datasets governamentais
- Dados cientÃ­ficos

**[Data.gov](https://data.gov/)**
- Dados do governo americano
- Abertos e gratuitos
- Diversas Ã¡reas (saÃºde, economia, clima)

</td>
<td width="50%">

#### ğŸ’¡ **Temas Sugeridos**

**SaÃºde:**
- Diabetes (Pima Indians)
- DoenÃ§as CardÃ­acas
- Custos MÃ©dicos
- COVID-19

**NegÃ³cios:**
- PrevisÃ£o de Vendas
- Churn de Clientes
- PreÃ§os de AÃ§Ãµes
- Marketing

**Social:**
- AnÃ¡lise de Sentimentos
- Fake News Detection
- Redes Sociais

**Ambiente:**
- PrevisÃ£o ClimÃ¡tica
- Qualidade do Ar
- Desastres Naturais

</td>
</tr>
</table>

### **CritÃ©rios de SeleÃ§Ã£o**

âœ… **Tamanho adequado** (mÃ­nimo 1000 registros)  
âœ… **Qualidade dos dados** (baixa taxa de missing values)  
âœ… **DocumentaÃ§Ã£o disponÃ­vel**  
âœ… **RelevÃ¢ncia do tema**  
âœ… **Variedade de features** (numÃ©ricas e categÃ³ricas)

---

## ğŸ“ˆ Exemplos de Resultados Esperados

### **VisualizaÃ§Ãµes TÃ­picas**

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Matriz de CorrelaÃ§Ã£o           â”‚
â”‚  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”          â”‚
â”‚  â”‚ 1 â”‚ . â”‚ . â”‚ . â”‚ . â”‚          â”‚
â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤          â”‚
â”‚  â”‚ . â”‚ 1 â”‚ . â”‚ . â”‚ . â”‚          â”‚
â”‚  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤          â”‚
â”‚  â”‚ . â”‚ . â”‚ 1 â”‚ . â”‚ . â”‚          â”‚
â”‚  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ComparaÃ§Ã£o de Modelos          â”‚
â”‚                                 â”‚
â”‚  Random Forest    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 92%  â”‚
â”‚  Neural Network   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  89%  â”‚
â”‚  SVM              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   86%  â”‚
â”‚  KNN              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    83%  â”‚
â”‚  Log. Regression  â–ˆâ–ˆâ–ˆâ–ˆ     80%  â”‚
â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Curva ROC                      â”‚
â”‚    â”‚                            â”‚
â”‚  1 â”‚         â”Œâ”€â”€â”€â”€â”€â”€            â”‚
â”‚    â”‚        /                   â”‚
â”‚    â”‚       /                    â”‚
â”‚    â”‚      /                     â”‚
â”‚  0 â””â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚    0              1              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### **Tabela Exemplo de Resultados**

| Modelo | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score | Tempo (s) |
|:------:|:--------:|:--------:|:------:|:--------:|:---------:|
| Random Forest | **92.3%** | 91.5% | 93.1% | 92.3% | 12.4 |
| Neural Network | 89.7% | **92.1%** | 87.3% | 89.6% | 45.2 |
| SVM | 86.4% | 85.9% | 87.0% | 86.4% | 8.7 |
| KNN | 83.2% | 84.1% | 82.3% | 83.2% | 3.1 |
| Log. Regression | 80.5% | 81.2% | 79.8% | 80.5% | 1.2 |

---

## ğŸ¯ Checklist de Entrega

### **DocumentaÃ§Ã£o**

- [ ] RelatÃ³rio tÃ©cnico completo (PDF)
- [ ] ApresentaÃ§Ã£o em slides (PDF/PPT)
- [ ] README detalhado (este arquivo)
- [ ] DocumentaÃ§Ã£o de cÃ³digo (docstrings)
- [ ] 3 artigos cientÃ­ficos analisados

### **CÃ³digo**

- [ ] Notebooks Jupyter organizados
- [ ] Scripts Python modularizados
- [ ] ComentÃ¡rios claros no cÃ³digo
- [ ] Requirements.txt atualizado
- [ ] RepositÃ³rio GitHub organizado

### **Dados**

- [ ] 3 datasets selecionados
- [ ] Dados de treino/validaÃ§Ã£o/teste
- [ ] DocumentaÃ§Ã£o das fontes
- [ ] DicionÃ¡rio de dados

### **Modelos**

- [ ] Modelos treinados salvos (.pkl/.h5)
- [ ] HiperparÃ¢metros documentados
- [ ] MÃ©tricas de avaliaÃ§Ã£o calculadas
- [ ] ComparaÃ§Ã£o entre modelos

### **Resultados**

- [ ] GrÃ¡ficos e visualizaÃ§Ãµes
- [ ] Tabelas comparativas
- [ ] AnÃ¡lise de feature importance
- [ ] InterpretaÃ§Ã£o dos resultados

### **ApresentaÃ§Ã£o**

- [ ] Slides preparados
- [ ] DemonstraÃ§Ã£o testada
- [ ] Tempo controlado (20 min)
- [ ] DivisÃ£o de responsabilidades

---

## ğŸ’¡ Dicas e Boas PrÃ¡ticas

### **Para AnÃ¡lise de Dados**

```python
# âœ… Sempre verificar dados ausentes
df.isnull().sum()

# âœ… Visualizar distribuiÃ§Ãµes
df.describe()
df.hist(figsize=(15,10))

# âœ… Detectar outliers
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

# âœ… Verificar balanceamento de classes
df['target'].value_counts()
```

### **Para Modelagem**

```python
# âœ… Sempre dividir dados antes de qualquer processamento
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# âœ… Usar validaÃ§Ã£o cruzada
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X_train, y_train, cv=5)

# âœ… Salvar modelos treinados
import joblib

joblib.dump(model, 'modelos/random_forest_model.pkl')

# âœ… Documentar hiperparÃ¢metros
best_params = {
    'n_estimators': 100,
    'max_depth': 10,
    'min_samples_split': 5
}
```

### **Para VisualizaÃ§Ã£o**

```python
# âœ… Usar paletas apropriadas
import seaborn as sns

sns.set_palette("husl")

# âœ… TÃ­tulos e labels claros
plt.title('ComparaÃ§Ã£o de AcurÃ¡cia entre Modelos', fontsize=14)
plt.xlabel('Modelo', fontsize=12)
plt.ylabel('AcurÃ¡cia (%)', fontsize=12)

# âœ… Salvar em alta resoluÃ§Ã£o
plt.savefig('visualizacoes/resultados/comparacao.png', 
            dpi=300, bbox_inches='tight')
```

---

## âš ï¸ Problemas Comuns e SoluÃ§Ãµes

<details>
<summary><b>Dados Desbalanceados</b></summary>

**Problema:** Classes com distribuiÃ§Ã£o muito desigual.

**SoluÃ§Ãµes:**
```python
# 1. Oversampling (SMOTE)
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# 2. Class weights
model = RandomForestClassifier(class_weight='balanced')

# 3. Undersampling
from imblearn.under_sampling import RandomUnderSampler
```

</details>

<details>
<summary><b>Overfitting</b></summary>

**Problema:** Modelo performa bem no treino mas mal no teste.

**SoluÃ§Ãµes:**
```python
# 1. RegularizaÃ§Ã£o
model = LogisticRegression(C=0.1, penalty='l2')

# 2. Dropout (redes neurais)
model.add(Dropout(0.3))

# 3. Early stopping
from keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=10)

# 4. Mais dados de treino ou data augmentation
```

</details>

<details>
<summary><b>Dados Ausentes</b></summary>

**Problema:** Muitos valores faltando no dataset.

**SoluÃ§Ãµes:**
```python
# 1. Remover se < 5% ausentes
df = df.dropna()

# 2. ImputaÃ§Ã£o simples
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')  # ou 'median', 'most_frequent'

# 3. ImputaÃ§Ã£o por KNN
from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=5)
```

</details>

---

## ğŸ“ Contato e Suporte

### **DÃºvidas sobre o Projeto**

- **Professor:** Noberto Maciel
- **Email:** [email do professor]
- **HorÃ¡rio de Atendimento:** [horÃ¡rios]

### **Recursos Ãšteis**

- ğŸ“– [DocumentaÃ§Ã£o Scikit-Learn](https://scikit-learn.org/)
- ğŸ“– [DocumentaÃ§Ã£o TensorFlow](https://www.tensorflow.org/)
- ğŸ“– [Pandas Documentation](https://pandas.pydata.org/)
- ğŸ’¬ [Stack Overflow](https://stackoverflow.com/)
- ğŸ’¬ [Kaggle Learn](https://www.kaggle.com/learn)

---

## ğŸ“… Cronograma Sugerido

<div align="center">

```mermaid
gantt
    title Cronograma Projeto A3
    dateFormat  YYYY-MM-DD
    section PreparaÃ§Ã£o
    SeleÃ§Ã£o de datasets           :done, 2025-09-15, 1w
    RevisÃ£o bibliogrÃ¡fica         :done, 2025-09-22, 2w
    section Desenvolvimento
    AnÃ¡lise exploratÃ³ria          :active, 2025-10-06, 1w
    PrÃ©-processamento            :2025-10-13, 1w
    Modelagem                    :2025-10-20, 2w
    section FinalizaÃ§Ã£o
    AnÃ¡lise comparativa          :2025-11-03, 3d
    RelatÃ³rio tÃ©cnico            :2025-11-03, 3d
    ApresentaÃ§Ã£o                 :2025-11-06, 1d
    section Entrega
    Entrega final                :milestone, 2025-11-06, 0d
    ApresentaÃ§Ã£o                 :milestone, 2025-11-13, 0d
```

</div>

---

## ğŸ† CritÃ©rios de AvaliaÃ§Ã£o

| CritÃ©rio | Peso | DescriÃ§Ã£o |
|:--------:|:----:|:----------|
| **Metodologia** | 25% | Rigor cientÃ­fico, escolha adequada de tÃ©cnicas |
| **ImplementaÃ§Ã£o** | 25% | Qualidade do cÃ³digo, modularizaÃ§Ã£o, documentaÃ§Ã£o |
| **Resultados** | 20% | Performance dos modelos, anÃ¡lises estatÃ­sticas |
| **AnÃ¡lise CrÃ­tica** | 15% | ComparaÃ§Ã£o com literatura, insights gerados |
| **ApresentaÃ§Ã£o** | 10% | Clareza, organizaÃ§Ã£o, domÃ­nio do conteÃºdo |
| **RelatÃ³rio** | 5% | FormataÃ§Ã£o ABNT, escrita tÃ©cnica |

**Nota MÃ¡xima:** 40 pontos

---

<div align="center">

## â­ Boa Sorte no Projeto!

<img src="https://user-images.githubusercontent.com/74038190/216122041-518ac897-8d92-4c6b-9b3f-ca01dcaf38ee.png" width="200" />

**Lembre-se:** A qualidade Ã© mais importante que a quantidade. Foque em fazer um trabalho bem fundamentado e com anÃ¡lises profundas!

---

<sub>ğŸ“§ Para dÃºvidas, consulte o professor ou os colegas de equipe</sub>

<sub>ğŸ”„ Documento atualizado: Outubro 2025</sub>

**[â¬† Voltar ao topo](#-projeto-a3-machine-learning-aplicado)**

**[â† Voltar ao README principal](../README.md)**

</div>
